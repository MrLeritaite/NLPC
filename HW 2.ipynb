{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TEST_BIO = \"TEST/biology/\"\n",
    "\n",
    "entire_path = os.path.join(TEST_BIO, 'class_11_biology_chapter_1_0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(entire_path, 'r') as file:\n",
    "    data = file.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences 13\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent = sent_tokenize(data)\n",
    "print(\"Number of sentences {}\".format(len(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens 253\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word = word_tokenize(data)\n",
    "print(\"Number of tokens {}\".format(len(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens 253\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import casual_tokenize\n",
    "casual = casual_tokenize(data)\n",
    "print(\"Number of tokens {}\".format(len(casual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens 253\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "mwe = MWETokenizer()\n",
    "print(\"Number of tokens {}\".format(len(mwe.tokenize(casual))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean number of tokens per sentence is 19\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean number of tokens per sentence is {}\".format(len(word) // len(sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stem = []\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "for token in casual:\n",
    "    porter_stem.append(porter.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanc_stem = []\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "for token in casual:\n",
    "    lanc_stem.append(lancaster.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stem = []\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')\n",
    "\n",
    "for token in casual:\n",
    "    snowball_stem.append(snowball.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.DataFrame(casual, columns=['original_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Porter'] = porter_stem\n",
    "dataFrame['Lancaster'] = lanc_stem\n",
    "dataFrame['Snowball'] = snowball_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_token</th>\n",
       "      <th>Porter</th>\n",
       "      <th>Lancaster</th>\n",
       "      <th>Snowball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>chapt</td>\n",
       "      <td>chapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>living</td>\n",
       "      <td>live</td>\n",
       "      <td>liv</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>’</td>\n",
       "      <td>’</td>\n",
       "      <td>’</td>\n",
       "      <td>’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>perspective</td>\n",
       "      <td>perspect</td>\n",
       "      <td>perspect</td>\n",
       "      <td>perspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>2019-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    original_token     Porter  Lancaster   Snowball\n",
       "0          chapter    chapter      chapt    chapter\n",
       "1                1          1          1          1\n",
       "2              the        the        the        the\n",
       "3           living       live        liv       live\n",
       "4            world      world      world      world\n",
       "..             ...        ...        ...        ...\n",
       "248              ’          ’          ’          ’\n",
       "249              s          s          s          s\n",
       "250    perspective   perspect   perspect   perspect\n",
       "251              .          .          .          .\n",
       "252      2019-2020  2019-2020  2019-2020  2019-2020\n",
       "\n",
       "[253 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 17),\n",
       " ('the', 13),\n",
       " ('.', 12),\n",
       " ('and', 11),\n",
       " ('living', 9),\n",
       " (',', 9),\n",
       " ('in', 6),\n",
       " ('organisms', 6),\n",
       " ('chapter', 4),\n",
       " ('a', 4)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "freq_dist = FreqDist(casual)\n",
    "freq_dist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " 'plant',\n",
       " '4',\n",
       " 'animal',\n",
       " 'i',\n",
       " 'is',\n",
       " 'science',\n",
       " 'processes',\n",
       " 'comprises',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'easily',\n",
       " 'perceive',\n",
       " 'difference',\n",
       " 'between',\n",
       " 'deified',\n",
       " '(',\n",
       " 'wind',\n",
       " 'sea',\n",
       " 'fire',\n",
       " 'etc',\n",
       " ')',\n",
       " 'common',\n",
       " 'feature',\n",
       " 'animate',\n",
       " 'objects',\n",
       " 'sense',\n",
       " 'awe',\n",
       " 'or',\n",
       " 'fear',\n",
       " 'they',\n",
       " 'evoked',\n",
       " 'beings',\n",
       " 'began',\n",
       " 'much',\n",
       " 'later',\n",
       " 'history',\n",
       " 'societies',\n",
       " 'indulged',\n",
       " 'anthropocentric',\n",
       " 'view',\n",
       " 'register',\n",
       " 'limited',\n",
       " 'progress',\n",
       " 'knowledge',\n",
       " 'systematic',\n",
       " 'monumental',\n",
       " 'brought',\n",
       " 'out',\n",
       " 'necessity',\n",
       " 'detailed',\n",
       " 'systems',\n",
       " 'identification',\n",
       " 'nomenclature',\n",
       " 'biggest',\n",
       " 'spin',\n",
       " 'off',\n",
       " 'studies',\n",
       " 'recognition',\n",
       " 'sharing',\n",
       " 'similarities',\n",
       " 'both',\n",
       " 'horizontally',\n",
       " 'vertically',\n",
       " 'present',\n",
       " 'day',\n",
       " 'are',\n",
       " 'related',\n",
       " 'each',\n",
       " 'other',\n",
       " 'also',\n",
       " 'ever',\n",
       " 'lived',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'revelation',\n",
       " 'humbled',\n",
       " 'led',\n",
       " 'cultural',\n",
       " 'movements',\n",
       " 'for',\n",
       " 'conservation',\n",
       " 'biodiversity',\n",
       " 'following',\n",
       " 'chapters',\n",
       " 'you',\n",
       " 'will',\n",
       " 'get',\n",
       " 'from',\n",
       " 'taxonomist',\n",
       " '’',\n",
       " 's',\n",
       " 'perspective',\n",
       " '2019-2020']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15, 7))\n",
    "freq_dist.plot(title=\"Frequencies of words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "pos = pos_tag(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in nltk.ne_chunk(pos):\n",
    "    if hasattr(chunk, 'label'):\n",
    "        print(chunk.label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_speech = []\n",
    "for i in pos[:]:\n",
    "    part_of_speech.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos = {'(': [], ')': [], ',': [], '.': [], 'CC': [], 'CD': [], 'DT': [], 'IN': [], 'JJ': []\n",
    "           , 'JJS': [], 'MD': [], 'NN': [], 'NNP': [], 'PRP': [], 'RB': [], 'RBR': [], 'TO': [], 'VB': []\n",
    "           , 'VBD': [], 'VBG': [], 'VBN': [], 'VBZ': [], 'WDT': [], 'NNS': [], 'VBP': []}\n",
    "res = np.unique(part_of_speech, axis = 0)\n",
    "for i in pos:\n",
    "    for j in range(len(res)):\n",
    "        if i[1] == res[j]:\n",
    "            dict_pos[res[j]].append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most = 0\n",
    "smallest = 100000\n",
    "for key, value in dict_pos.items():\n",
    "    if isinstance(value, list):\n",
    "        if most < len(value):\n",
    "            most = len(value)\n",
    "            key_most = key\n",
    "        if smallest > len(value):\n",
    "            smallest = len(value)\n",
    "            key_smallest = key\n",
    "print(\"Most common:{} {}\".format(key_most, most))\n",
    "print(\"Smallest :{} {}\".format(key_smallest, smallest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
